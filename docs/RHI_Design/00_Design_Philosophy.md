# RHI 設計仕様 — 設計哲学

グラフィックスAPI抽象層（RHI: Render Hardware Interface）を設計する際の
根本的な原則と設計判断の指針。

---

## 1. 基本設計哲学

### 1.1 最大公倍数アプローチ

#### 意図（Intent）
各プラットフォームの「最小限の共通機能」ではなく、
「すべてのプラットフォームの機能を統合した最大セット」をAPI面として公開する。

#### 要件（Requirements）
- RHI APIは全バックエンドの機能和集合を提供すること
- サポートされない機能はケイパビリティクエリで判別可能であること
- フォールバックパスの提供は呼び出し側の責務とすること

#### 不変条件（Invariants）
- ケイパビリティフラグがfalseの機能を呼び出した場合、動作は未定義ではなくエラーとすること
- フラグ値はバックエンド初期化後に確定し、以降変更されないこと

```
┌─────────────────────────────────────────────────────────┐
│                    RHI API Surface                       │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐    │
│  │ D3D12   │  │ Vulkan  │  │ Metal   │  │ OpenGL  │    │
│  │ 機能    │  │ 機能    │  │ 機能    │  │ 機能    │    │
│  └─────────┘  └─────────┘  └─────────┘  └─────────┘    │
│                                                          │
│  最小公約数アプローチ: 全APIで使える機能のみ ✗          │
│  最大公倍数アプローチ: 全APIの機能を統合 ✓              │
└─────────────────────────────────────────────────────────┘
```

#### 設計判断（Design Decisions）

**なぜ最小公約数ではないか:**
- ハイエンド機能（レイトレーシング、メッシュシェーダー等）を諦めることになる
- プラットフォーム固有の最適化の余地が失われる
- 将来の機能拡張に対応しづらい

**ケイパビリティクエリのパターン:**
```cpp
// ERHIFeature 列挙型で機能を識別し、ERHIFeatureSupport で3段階のサポート状態を返す。
// 個別のboolフラグやティア列挙型ではなく、統一的なクエリインターフェースを使用する。

enum class ERHIFeature : uint32 {
    RayTracing,
    MeshShaders,
    Bindless,
    VariableRateShading,
    WorkGraphs,
    // ...
};

enum class ERHIFeatureSupport : uint8 {
    Unsupported,       // 未サポート（ハードウェア非対応）
    RuntimeDependent,  // ランタイム依存（ドライバ確認必要）
    RuntimeGuaranteed, // ランタイム保証（必ずサポート）
};

// IDynamicRHI::GetFeatureSupport() で問い合わせる
ERHIFeatureSupport support = rhi->GetFeatureSupport(ERHIFeature::RayTracing);
if (IsFeatureSupported(support)) {
    // レイトレーシングパス
} else {
    // フォールバックパス
}
```

> **参考: UE5実装**
> UE5では `GRHISupportsRayTracing` 等のグローバル変数と
> `ERayTracingTier` 列挙型でケイパビリティを公開している。

---

### 1.2 ゼロコスト抽象化の追求

#### 意図（Intent）
抽象化レイヤーのCPUオーバーヘッドを可能な限りゼロに近づける。
グラフィックスAPIは毎フレーム数万回呼ばれるため、1呼び出しあたりのコストが直接FPSに影響する。

#### 要件（Requirements）
- 出荷ビルドではバックエンド関数呼び出しがインライン化可能であること
- コマンドは構造体として定義し、静的ディスパッチを用いること
- 開発時のディスパッチテーブル（関数ポインタ）経由は許容するが、出荷時には除去すること

#### 不変条件（Invariants）
- 出荷ビルドでのコマンド記録CPUコストはネイティブAPI直接呼び出しの1.05倍以内であること
- 開発ビルドでは関数ポインタ間接呼び出し1回分（1.2倍程度）を許容する

```cpp
// 方式1: ディスパッチテーブル（関数ポインタ）— 開発時
// 間接呼び出し1回だが、vtableよりシンプル（thisポインタ不要）
struct RHIDispatchTable {
    RHIBuffer* (*CreateBuffer)(const BufferDesc&);
    void       (*Draw)(RHICommandContext*, uint32_t vertexCount, ...);
    // ...
};
extern RHI_API RHIDispatchTable GRHIDispatchTable;

// 呼び出し: GRHIDispatchTable.Draw(ctx, 36, 1, 0, 0);

// 方式2: コンパイル時選択 — 出荷時
// NS_RHI_DISPATCH マクロで統一。出荷ビルドでは直接呼び出しに展開される。
#if NS_BUILD_SHIPPING && defined(NS_RHI_STATIC_BACKEND)
  // 例: NS_RHI_STATIC_BACKEND = D3D12 の場合
  //     NS_RHI_DISPATCH(Draw, ctx, ...) → D3D12_Draw(ctx, ...) に展開
  #define NS_RHI_DISPATCH(func, ...) \
      ::NS::RHI::NS_RHI_EXPAND(NS_RHI_STATIC_BACKEND, func)(__VA_ARGS__)
#else
  // 開発ビルド: ディスパッチテーブル経由
  #define NS_RHI_DISPATCH(func, ...) \
      ::NS::RHI::GRHIDispatchTable.func(__VA_ARGS__)
#endif

// 方式3: コマンド構造体 + 静的Execute（遅延実行パス）
struct CmdDraw {
    static constexpr ERHICommandType kType = ERHICommandType::Draw;
    RHICommandHeader header;      // コマンドタイプ + サイズ + 次コマンドオフセット
    uint32_t vertexCount;
    uint32_t instanceCount;
    uint32_t startVertex;
    uint32_t startInstance;

    static void Execute(IRHICommandContext* ctx, const CmdDraw& cmd);
};
```

#### なぜ仮想関数を使わないか

| 項目 | 仮想関数 | ディスパッチテーブル | コンパイル時選択 |
|------|---------|-------------------|----------------|
| 間接呼び出し | vtable + thisポインタ | 関数ポインタ1回 | なし |
| インライン化 | 不可能 | 不可能 | 可能 |
| ランタイム切替 | 可能 | 可能 | 不可能 |
| クラス階層 | 必要 | 不要 | 不要 |
| コード複雑さ | 低 | 低 | 中（マクロ/namespace） |

本設計ではディスパッチテーブル（開発時）→ コンパイル時選択（出荷時）の段階的移行を採用する。

---

### 1.3 明示的制御の優先

#### 意図（Intent）
暗黙の動作（ドライバーによる自動状態遷移、隠れたメモリ割り当て等）を排除し、
パフォーマンスの予測可能性とデバッグの容易さを確保する。

#### 要件（Requirements）
- リソース状態遷移は呼び出し側が明示的にバリアを発行すること
- メモリ割り当てはリソース作成時に明示的に行うこと
- 同期ポイントは呼び出し側が明示的にフェンスを配置すること

#### 不変条件（Invariants）
- RHI層がバリアを自動挿入することはない（検証レイヤーを除く）
- リソース作成以外でGPUメモリ割り当てが発生しない

```cpp
// 悪い例: 暗黙のリソース状態遷移
void DrawMesh(Texture* texture) {
    SetTexture(0, texture);  // ドライバーが勝手に遷移（非効率、予測不能）
    Draw();
}

// 良い例: 明示的なバリア
void DrawMesh(CommandList& cmdList, Texture* texture) {
    cmdList.Transition(TransitionInfo(
        texture,
        ResourceState::CopyDest,      // 前の状態
        ResourceState::ShaderResource  // 新しい状態
    ));
    cmdList.SetTexture(0, texture);
    cmdList.Draw();
}
```

---

## 2. リソース管理原則

### 2.1 参照カウントによるライフタイム管理

#### 意図（Intent）
GPUリソースの寿命を安全に管理する。GPUが使用中のリソースをCPU側で
解放してしまうと未定義動作になるため、参照カウント + 遅延削除で防ぐ。

#### 要件（Requirements）
- 全GPUリソースは参照カウントを持つこと
- 参照カウントがゼロになった時点で即削除せず、遅延削除キューに入れること
- スマートポインタ（RefCountPtr）でRAII管理すること

#### 不変条件（Invariants）
- GPUが参照中のリソースが解放されることはない
- 遅延削除キューのフラッシュはフレーム境界でのみ行われる

```cpp
class IRHIResource {
    mutable std::atomic<uint32_t> m_refCount{1};  // 初期値1（作成時に所有権あり）
public:
    uint32_t AddRef() const { return ++m_refCount; }
    uint32_t Release() const {
        uint32_t newCount = --m_refCount;
        if (newCount == 0) {
            OnZeroRefCount();  // 即削除しない（遅延削除キューへ）
        }
        return newCount;
    }
protected:
    virtual void OnZeroRefCount() const;  // デフォルトは即削除、オーバーライドで遅延削除
};
```

### 2.2 遅延削除パターン

#### 意図（Intent）
GPUがリソースを使い終わるまで実際の解放を遅延させる。
GPUは2-3フレーム遅れでコマンドを実行しているため、CPUで Release() した時点では
まだGPU側で参照されている可能性がある。

#### データフロー（Data Flow）
```
フレーム N:     リソース使用 → Release() 呼び出し
                              ↓
                      遅延削除キューに追加（フェンス値を記録）
                              ↓
フレーム N+1:   GPUがフレームN完了を待機
                              ↓
フレーム N+2:   フェンス値超過 → 実際のリソース解放
```

#### 不変条件（Invariants）
- 遅延削除キューのエントリは、記録したフェンス値をGPUが超過するまで削除されない
- フレーム開始時に完了済みフェンスのリソースのみ解放する

### 2.3 Transient（一時的）リソースの最適化

#### 意図（Intent）
フレーム内でのみ使用するリソース（シャドウマップ、G-Buffer等）は
同一メモリ領域を時分割で共有（エイリアシング）し、メモリ消費を削減する。

#### 要件（Requirements）
- フレームスコープのアロケータがリソースの生存期間を追跡すること
- 生存期間が重ならないリソース同士は同一メモリを共有できること
- 使用完了宣言により即座にメモリ再利用可能とすること

```
フレーム内のリソースタイムライン:

時間 →
┌────────────┐
│ Shadow Map │  使用期間: T0-T2
└────────────┘
              ┌────────────┐
              │ G-Buffer A │  使用期間: T2-T4
              └────────────┘
                            ┌────────────┐
                            │ G-Buffer B │  使用期間: T4-T6
                            └────────────┘

メモリ共有:
┌─────────────────────────────────────────┐
│           同一メモリ領域                 │
│  Shadow Map → G-Buffer A → G-Buffer B   │
└─────────────────────────────────────────┘
```

#### 不変条件（Invariants）
- 生存期間が重なるリソース同士はエイリアシングしてはならない
- Transient リソースはフレーム境界を跨いで使用してはならない

---

## 3. コマンドモデル

### 3.1 遅延実行モデル

#### 意図（Intent）
描画コマンドを記録時に即実行せず、バッファに蓄積して一括実行する。
これにより記録スレッドと実行スレッドを分離し、並列性を確保する。

#### データフロー（Data Flow）
```
記録フェーズ（レンダースレッド）:
┌─────────────────────────────────────┐
│ cmdList.SetPipeline(pso)            │ → メモリに記録
│ cmdList.SetVertexBuffer(vb)         │ → メモリに記録
│ cmdList.Draw(100)                   │ → メモリに記録
└─────────────────────────────────────┘

実行フェーズ（RHIスレッド/GPUスレッド）:
┌─────────────────────────────────────┐
│ 記録されたコマンドを順次実行        │
│ → ネイティブAPI (D3D12/Vulkan等) に変換・送信 │
└─────────────────────────────────────┘
```

#### 要件（Requirements）
- コマンドはリニアアロケータで高速に確保すること（malloc禁止）
- アロケータはフレーム毎にリセットして再利用すること
- コマンドリスト間のメモリ競合がないこと（スレッドローカル）

#### 不変条件（Invariants）
- 記録されたコマンドは記録順に実行される（順序保証）
- コマンド記録中にGPU副作用は発生しない

### 3.2 Bypass パターン

#### 意図（Intent）
デバッグや初期化等、即時実行が必要な場面では遅延キューをバイパスできる。

#### 責務（Responsibilities）
- Immediate モードのコマンドリストは即座にバックエンドAPIを呼び出す
- 通常のコマンドリストはバッファに記録するのみ

```cpp
void CommandList::Draw(uint32_t base, uint32_t prims, uint32_t instances) {
    if (IsImmediate()) {
        context->Draw(base, prims, instances);  // 即時実行
    } else {
        auto* cmd = AllocCommand<CmdDraw>(base, prims, instances);
        LinkCommand(cmd);  // バッファに記録
    }
}
```

### 3.3 並列コマンド記録

#### 意図（Intent）
複数スレッドで独立にコマンドリストを記録し、後でマージすることで
マルチコアCPUの性能を活用する。

#### データフロー（Data Flow）
```
Thread 0: ├─ cmdList0: DrawChunk(0) ─┤
Thread 1: ├─ cmdList1: DrawChunk(1) ─┤  → Merge → Submit
Thread 2: ├─ cmdList2: DrawChunk(2) ─┤
```

#### 不変条件（Invariants）
- 各コマンドリストは一つのスレッドのみが書き込むこと
- マージ後の実行順序はマージ順に決定される

---

## 4. スレッディングモデル

### 4.1 スレッド分離原則

#### 意図（Intent）
ゲームロジック・レンダリング・GPU送信を異なるスレッドで並列実行し、
CPU使用率を最大化する。

#### データフロー（Data Flow）
```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│ Game Thread │───→│Render Thread│───→│ RHI Thread  │───→ GPU
└─────────────┘    └─────────────┘    └─────────────┘
     │                   │                   │
     │ シーン更新        │ 可視性計算        │ APIコール
     │ 入力処理          │ 描画コマンド生成  │ リソース管理
     │ AI/物理           │ カリング          │ GPU同期
     └───────────────────┴───────────────────┘
            それぞれ独立して並列実行
```

#### 責務（Responsibilities）

| スレッド | 責務 | 触ってはならないもの |
|----------|------|---------------------|
| Game Thread | シーングラフ更新、入力処理 | GPUリソース直接操作 |
| Render Thread | 可視性判定、コマンドリスト記録 | GPUメモリ割り当て |
| RHI Thread | ネイティブAPI呼び出し、GPU同期 | ゲームオブジェクト |

### 4.2 パイプライン並列性

#### 意図（Intent）
Graphics キューと AsyncCompute キューを並列に実行し、
GPUのアイドル時間を削減する。

```
GPU実行タイムライン:

Graphics Queue:  ├─Draw A─┼─Draw B─┼─Draw C─┤
                                   ↓ 同期点
AsyncCompute:           ├─Compute X─┼─Compute Y─┤

時間 →

両キューは独立して進行し、明示的な同期点でのみ待機
```

#### 不変条件（Invariants）
- キュー間の同期は明示的なフェンスのみで行う
- あるキューのリソースを別キューで使う前に遷移バリアが必要

---

## 5. 状態管理原則

### 5.1 明示的状態追跡

#### 意図（Intent）
リソースの現在の状態（レンダーターゲット、シェーダーリソース等）を
RHI側で追跡し、不正な状態遷移を検出する。

#### 要件（Requirements）
- 各リソースは現在のアクセス状態を保持すること
- サブリソース（ミップレベル、配列スライス）単位で状態管理できること
- 状態遷移はバッチ化して一括発行できること

#### 不変条件（Invariants）
- リソースは宣言された状態と実際のGPU使用が一致していなければならない
- 同一リソースの読み取り状態は複数同時に設定できるが、書き込み状態は排他的

### 5.2 不変状態の焼き付け（PSO）

#### 意図（Intent）
描画中に変更されない状態（シェーダー、ブレンド、ラスタライザ等）を
Pipeline State Object に焼き付けて、GPUドライバーの最適化を促進する。

#### 責務（Responsibilities）
- **PSOに含まれる（不変）:** シェーダー、ブレンド状態、ラスタライザ状態、深度ステンシル状態
- **PSO外（動的）:** ビューポート、シザー矩形、ステンシル参照値

#### 設計判断（Design Decisions）
- PSOは作成後イミュータブル → GPU側でコンパイル・最適化可能
- 動的状態を最小限に保つことでドローコールのオーバーヘッドを削減
- PSOキャッシュでハッシュベースの重複排除を行う

### 5.3 バインディングモデル

#### 意図（Intent）
シェーダーにリソースを渡す仕組みを提供する。
従来のスロットベースとモダンなバインドレスの両方をサポートする。

```
従来のスロットベース:
┌─────────────────────────────────────┐
│ Slot 0: Texture A                   │
│ Slot 1: Texture B                   │
│ Slot 2: Buffer C                    │
└─────────────────────────────────────┘
変更のたびにディスクリプタ更新（CPUコスト）

バインドレス:
┌─────────────────────────────────────┐
│ Global Descriptor Heap              │
│ [0] [1] [2] [3] [4] [5] [6] ...    │
│  ↑                                  │
│ シェーダーがインデックスで直接参照  │
└─────────────────────────────────────┘
バインディング変更なし（CPUコスト低減）
```

#### 設計判断（Design Decisions）
- スロットベースは互換性が高い（全API対応）
- バインドレスは高スループット（描画コール間のバインディング変更不要）
- 段階的導入: レイトレーシングのみ → 全シェーダー の2段階

---

## 6. 同期プリミティブ

### 6.1 フェンスの階層

#### 意図（Intent）
同期の粒度に応じた複数レベルのフェンスを提供し、
必要最小限の同期でパイプラインストールを回避する。

```
┌─────────────────────────────────────────────────────┐
│ Level 1: フレームフェンス                           │
│   フレーム全体の完了を待機                          │
│   用途: スワップチェーン、リソース削除              │
├─────────────────────────────────────────────────────┤
│ Level 2: パイプラインフェンス                       │
│   特定パイプラインの完了を待機                      │
│   用途: Graphics ↔ AsyncCompute 同期               │
├─────────────────────────────────────────────────────┤
│ Level 3: コマンドリストフェンス                     │
│   特定コマンドリストの完了を待機                    │
│   用途: CPU読み取り、マップ操作                     │
├─────────────────────────────────────────────────────┤
│ Level 4: メモリバリア                               │
│   特定リソースのキャッシュフラッシュ                │
│   用途: UAV ↔ SRV 遷移                             │
└─────────────────────────────────────────────────────┘
```

#### 不変条件（Invariants）
- 上位レベルのフェンスは下位レベルを暗黙的に含む
- フェンスの待機はデッドロックを避けるため、同一キュー内でのセルフ待機を禁止

### 6.2 バリアバッチング

#### 意図（Intent）
個別のバリア発行はGPUパイプラインをストールさせるため、
複数のバリアをまとめて一度に発行する。

#### 不変条件（Invariants）
- バッチ内のバリアは独立（相互依存なし）であること
- 同一リソースに対する連続遷移 A→B, B→C は A→C に統合すること

### 6.3 スプリットバリア

#### 意図（Intent）
バリアの開始と終了を分離し、その間に無関係な作業を挿入して
GPUパイプラインのバブルを埋める。

```
通常のバリア:
  ├─ Barrier ─┤  ← GPUアイドル
  │           │
  ▼           ▼
 遷移開始   遷移完了 → 使用開始

スプリットバリア:
  ├─ BeginTransition ─┤
  │   他の無関係な作業  │  ← GPUアイドルなし
  ├─ EndTransition ───┤ → 使用開始
```

---

## 7. エラー処理原則

### 7.1 フェイルファスト

#### 意図（Intent）
無効な状態を早期に検出してクラッシュさせる。
不正な状態が伝播してGPUクラッシュやデータ破損になるのを防ぐ。

#### 要件（Requirements）
- デバッグビルドではnullチェック、範囲チェック、フラグ検証を行うこと
- リリースビルドでは検証コードを完全除去すること（ゼロコスト）

### 7.2 検証レイヤー

#### 意図（Intent）
デバッグ時にRHI呼び出しの正しさを検証するラッパーレイヤー。
D3D12やVulkanの検証レイヤーが捕捉しないRHI固有のミスを検出する。

#### 責務（Responsibilities）
- パイプライン状態のバインド漏れ検出
- リソースバインディングの整合性チェック
- リソース状態遷移の正当性検証
- コマンド順序の論理的妥当性検証

#### 設計判断（Design Decisions）
- バックエンドをラップするデコレータパターン
- ビルド設定で有効/無効を切り替え（リリースでは完全除去）

### 7.3 GPUクラッシュ診断

#### 意図（Intent）
GPUクラッシュ時に「どのコマンドでクラッシュしたか」を特定する仕組み。

#### 要件（Requirements）
- Breadcrumb（パンくず）マーカーをコマンド間に挿入できること
- クラッシュ時に最後に完了したマーカーを報告できること
- ベンダーSDK（NVIDIA Aftermath等）と連携できる拡張ポイントがあること

#### データフロー（Data Flow）
```
コマンド実行中:
  [Marker: ShadowPass] → Draw → Draw → [Marker: GBuffer] → Draw → 💥 クラッシュ

診断出力:
  最後に完了: ShadowPass
  実行中:     GBuffer
  → GBufferパスの描画中にクラッシュ発生
```

---

## 8. 拡張性原則

### 8.1 プラットフォーム拡張ポイント

#### 意図（Intent）
ベンダー固有機能やプラットフォーム固有最適化を、
コアRHIを壊さずに追加できる仕組み。

#### 要件（Requirements）
- ネイティブデバイスハンドル（ID3D12Device*, VkDevice等）へのアクセス手段
- 名前ベースの拡張クエリ機構
- 拡張インターフェース取得メソッド

```cpp
class RHIBackend {
public:
    // 標準API
    virtual void Draw(...) = 0;

    // ネイティブアクセス（型安全なキャストは呼び出し側責務）
    virtual void* GetNativeDevice() { return nullptr; }

    // 拡張クエリ
    virtual bool SupportsExtension(const char* name) { return false; }
    virtual void* GetExtensionInterface(const char* name) { return nullptr; }
};
```

### 8.2 機能フラグによる条件分岐

#### 意図（Intent）
コンパイル時と実行時の2層で機能の有無を判定し、
コードサイズ最適化とランタイム柔軟性を両立する。

#### 要件（Requirements）
- コンパイル時フラグ: プラットフォーム固有コードの条件コンパイル
- 実行時フラグ: ハードウェアケイパビリティに基づく動的分岐
- ティアシステム: 段階的な機能レベルの表現

```cpp
// コンパイル時フラグ（プラットフォームごとのコードパス）
#if PLATFORM_SUPPORTS_MESH_SHADERS
    // メッシュシェーダーパイプライン
#endif

// 実行時フラグ（ハードウェア依存）
if (caps.supportsMeshShaders) {
    DrawMeshShaderPipeline();
} else {
    DrawTraditionalPipeline();
}

// ティア（段階的機能レベル）
switch (caps.rayTracingTier) {
case RayTracingTier::NotSupported: break;
case RayTracingTier::Tier1_0: /* 基本RT */ break;
case RayTracingTier::Tier1_1: /* 高度RT */ break;
}
```

---

## 9. パフォーマンス原則

### 9.1 CPUオーバーヘッド最小化

#### 意図（Intent）
API呼び出し回数を減らし、CPUがボトルネックになることを防ぐ。

#### 設計判断（Design Decisions）

| 手法 | API呼び出し数 | 説明 |
|------|:------------:|------|
| 個別描画 | 3N | SetVB + SetIB + Draw × N回 |
| インスタンシング | 3 | 1回の描画で全インスタンス |
| Indirect描画 | 3 | GPUが描画パラメータを決定 |
| Shader Bundle | 1 | 事前記録済みコマンドバッチ再生 |

### 9.2 GPUアイドル時間の排除

#### 意図（Intent）
GPUが常に作業を持つようにスケジューリングする。

```
悪い例（GPUアイドルあり）:
CPU: ├─Record─┼─Wait─┼─Record─┼─Wait─┤
GPU:          ├─Execute─┤    ├─Execute─┤
                    ↑ アイドル

良い例（パイプライン化）:
CPU: ├─Frame N─┼─Frame N+1─┼─Frame N+2─┤
GPU:     ├─Frame N-1─┼─Frame N─┼─Frame N+1─┤
     常にGPUに作業がある（2-3フレーム遅延）
```

#### 不変条件（Invariants）
- N frames in flight: CPU は GPU より最大 N フレーム先行可能
- N は通常 2-3（レイテンシと並列性のトレードオフ）

### 9.3 メモリ帯域幅の最適化

#### 意図（Intent）
データレイアウトとアクセスパターンを最適化し、
GPU/CPUのキャッシュヒット率を最大化する。

#### 要件（Requirements）
- 頂点データは頻繁にアクセスするフィールドを先頭に配置
- 圧縮フォーマット（10:10:10:2法線、half UV等）を活用
- アライメントをキャッシュライン境界に合わせる

---

## 10. 設計パターンまとめ

### 10.1 主要パターン一覧

| パターン | 用途 | 適用箇所 |
|----------|------|----------|
| **コマンド** | 遅延実行 | 描画コマンド記録 |
| **ファクトリ** | リソース作成 | バックエンドの Create* メソッド群 |
| **ストラテジー** | バックエンド切り替え | D3D12/Vulkan/Metal 実装 |
| **フライウェイト** | 状態共有 | PSO キャッシュ |
| **RAII** | ライフタイム管理 | RefCountPtr、スコープガード |
| **プール** | オブジェクト再利用 | クエリプール、ディスクリプタプール |
| **バッチ** | 呼び出し効率化 | バリアバッチ、シェーダーパラメータ |
| **デコレータ** | 機能追加 | 検証レイヤー |

### 10.2 新機能追加チェックリスト

新しいRHI機能を追加する際の設計チェックリスト:

- [ ] ゼロコスト抽象化か？（vtableルックアップなし）
- [ ] 明示的制御か？（暗黙の副作用なし）
- [ ] スレッドセーフか？（どのスレッドから呼ばれるか明記）
- [ ] 遅延削除に対応しているか？（GPUライフタイム考慮）
- [ ] バッチ化可能か？（複数呼び出しをまとめられるか）
- [ ] 検証レイヤーでカバーされているか？
- [ ] ケイパビリティクエリがあるか？（オプション機能の場合）
- [ ] パフォーマンス計測可能か？（プロファイリングフック）
- [ ] フォールバックパスがあるか？（非対応プラットフォーム）

---

## 結論

RHI設計の核心原則:

1. **最大公倍数**: 全プラットフォームの機能和集合を公開
2. **ゼロコスト抽象化**: 抽象化のCPUオーバーヘッドを排除
3. **明示的制御**: 暗黙の動作を排除し予測可能性を確保
4. **遅延実行 + 遅延削除**: GPUとCPUのライフタイム不一致を安全に解決
5. **スレッド分離**: 記録・実行・同期を異なるスレッドで並列化
6. **拡張性**: ケイパビリティクエリと拡張ポイントで将来の機能に対応
